{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0ac862",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:06.480528Z",
     "iopub.status.busy": "2025-12-13T07:31:06.480323Z",
     "iopub.status.idle": "2025-12-13T07:31:10.749735Z",
     "shell.execute_reply": "2025-12-13T07:31:10.748744Z"
    },
    "papermill": {
     "duration": 4.274969,
     "end_time": "2025-12-13T07:31:10.751141",
     "exception": false,
     "start_time": "2025-12-13T07:31:06.476172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "source_path = '/kaggle/input/whirl-repo/WHIRL'\n",
    "working_path = '/kaggle/working/WHIRL'\n",
    "\n",
    "if not os.path.exists(working_path):\n",
    "    print(\"Copying repository to writable directory...\")\n",
    "    shutil.copytree(source_path, working_path)\n",
    "else:\n",
    "    print(\"Repository already exists in working directory.\")\n",
    "\n",
    "os.chdir(working_path)\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "\n",
    "sys.path.append(working_path)\n",
    "\n",
    "print(\"Installing dependencies...\")\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da09f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:10.759018Z",
     "iopub.status.busy": "2025-12-13T07:31:10.758423Z",
     "iopub.status.idle": "2025-12-13T07:31:10.764925Z",
     "shell.execute_reply": "2025-12-13T07:31:10.764236Z"
    },
    "papermill": {
     "duration": 0.011433,
     "end_time": "2025-12-13T07:31:10.766026",
     "exception": false,
     "start_time": "2025-12-13T07:31:10.754593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "dfl_path = '/kaggle/working/WHIRL/dfl'\n",
    "\n",
    "if dfl_path not in sys.path:\n",
    "    sys.path.append(dfl_path)\n",
    "    print(f\"Added {dfl_path} to Python path.\")\n",
    "\n",
    "\n",
    "try:\n",
    "    import config\n",
    "    print(\"SUCCESS: config module found.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Still can't find config. {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546ce07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:10.772554Z",
     "iopub.status.busy": "2025-12-13T07:31:10.772361Z",
     "iopub.status.idle": "2025-12-13T07:31:28.445217Z",
     "shell.execute_reply": "2025-12-13T07:31:28.444386Z"
    },
    "papermill": {
     "duration": 17.677437,
     "end_time": "2025-12-13T07:31:28.446334",
     "exception": false,
     "start_time": "2025-12-13T07:31:10.768897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4d68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.454641Z",
     "iopub.status.busy": "2025-12-13T07:31:28.453880Z",
     "iopub.status.idle": "2025-12-13T07:31:28.463880Z",
     "shell.execute_reply": "2025-12-13T07:31:28.463108Z"
    },
    "papermill": {
     "duration": 0.015128,
     "end_time": "2025-12-13T07:31:28.465004",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.449876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enhanced Data Generator with Multiple Beta Profiles\n",
    "\n",
    "def generate_real_world_proxy_transitions(n_arms, n_states=2, seed=None, \n",
    "                                         beta_a=2, beta_b=2, profile_name=\"Standard\"):\n",
    "    \"\"\"\n",
    "    Enhanced generator with configurable Beta parameters for sensitivity analysis.\n",
    "    \n",
    "    Args:\n",
    "        beta_a, beta_b: Beta distribution parameters for grit\n",
    "        profile_name: Descriptive name for this parameter set\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    transitions = np.zeros((n_arms, 2, 2, 2))\n",
    "    metadata = {\n",
    "        'grit': np.zeros(n_arms),\n",
    "        'self_recovery': np.zeros(n_arms),\n",
    "        'intervention_lift': np.zeros(n_arms),\n",
    "        'profile': profile_name,\n",
    "        'beta_params': (beta_a, beta_b)\n",
    "    }\n",
    "    \n",
    "    for i in range(n_arms):\n",
    "        grit = np.random.beta(a=beta_a, b=beta_b)\n",
    "        metadata['grit'][i] = grit\n",
    "        \n",
    "        p_stay_active = grit * 0.9\n",
    "        p_self_recovery = np.random.beta(a=1, b=5) * 0.2\n",
    "        metadata['self_recovery'][i] = p_self_recovery\n",
    "        \n",
    "        # Passive transitions\n",
    "        transitions[i, 0, 0, 1] = p_self_recovery\n",
    "        transitions[i, 0, 0, 0] = 1 - p_self_recovery\n",
    "        transitions[i, 0, 1, 1] = p_stay_active\n",
    "        transitions[i, 0, 1, 0] = 1 - p_stay_active\n",
    "        \n",
    "        # Active transitions\n",
    "        lift = 0.4 * (1 - grit)\n",
    "        metadata['intervention_lift'][i] = lift\n",
    "        \n",
    "        p_active_recovery = np.clip(p_self_recovery + lift, 0, 0.95)\n",
    "        p_active_retention = np.clip(p_stay_active + (lift/2), 0, 0.99)\n",
    "        \n",
    "        transitions[i, 1, 0, 1] = p_active_recovery\n",
    "        transitions[i, 1, 0, 0] = 1 - p_active_recovery\n",
    "        transitions[i, 1, 1, 1] = p_active_retention\n",
    "        transitions[i, 1, 1, 0] = 1 - p_active_retention\n",
    "    \n",
    "    return transitions.astype(np.float32), metadata\n",
    "\n",
    "\n",
    "def validate_data_quality(transitions, metadata):\n",
    "    \"\"\"Comprehensive validation with monotonicity checks.\"\"\"\n",
    "    n = len(transitions)\n",
    "    report = {\n",
    "        'n_beneficiaries': n,\n",
    "        'profile': metadata['profile'],\n",
    "        'beta_params': metadata['beta_params'],\n",
    "        'grit_mean': np.mean(metadata['grit']),\n",
    "        'grit_std': np.std(metadata['grit']),\n",
    "        'bimodality_coefficient': None,\n",
    "        'monotonicity_violations': 0,\n",
    "        'intervention_efficacy': 0\n",
    "    }\n",
    "    \n",
    "    grit = metadata['grit']\n",
    "    m3 = stats.skew(grit)\n",
    "    m4 = stats.kurtosis(grit, fisher=False)\n",
    "    bc = (m3**2 + 1) / m4 if m4 != 0 else 0\n",
    "    report['bimodality_coefficient'] = bc\n",
    "    \n",
    "    for i in range(n):\n",
    "        P = transitions[i]\n",
    "        if P[1, 0, 1] < P[0, 0, 1] - 1e-6 or P[1, 1, 1] < P[0, 1, 1] - 1e-6:\n",
    "            report['monotonicity_violations'] += 1\n",
    "        else:\n",
    "            report['intervention_efficacy'] += 1\n",
    "    \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023fb96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.472312Z",
     "iopub.status.busy": "2025-12-13T07:31:28.472091Z",
     "iopub.status.idle": "2025-12-13T07:31:28.483565Z",
     "shell.execute_reply": "2025-12-13T07:31:28.482884Z"
    },
    "papermill": {
     "duration": 0.016499,
     "end_time": "2025-12-13T07:31:28.484630",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.468131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONSTRAINT ENFORCEMENT METHODS\n",
    "\n",
    "\n",
    "class ConstraintMethod:\n",
    "    \"\"\"Base class for constraint enforcement methods.\"\"\"\n",
    "    \n",
    "    def __init__(self, epsilon=1e-3):\n",
    "        self.epsilon = epsilon\n",
    "        self.name = \"Base\"\n",
    "    \n",
    "    def project(self, rewards):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def check_violations(self, rewards):\n",
    "        \"\"\"Counting number of constraint violations.\"\"\"\n",
    "        violations = np.sum(rewards[:, 1] < rewards[:, 0] - self.epsilon)\n",
    "        return violations\n",
    "\n",
    "\n",
    "class ProjectedGradient(ConstraintMethod):\n",
    "    \"\"\"Projected Gradient Descent - projects to feasible region after each update.\"\"\"\n",
    "    \n",
    "    def __init__(self, epsilon=1e-3):\n",
    "        super().__init__(epsilon)\n",
    "        self.name = \"Projected_Gradient\"\n",
    "    \n",
    "    def project(self, rewards):\n",
    "        \"\"\"Projects rewards to satisfy R(1) >= R(0).\"\"\"\n",
    "        r_sick = rewards[:, 0]\n",
    "        r_healthy = rewards[:, 1]\n",
    "        \n",
    "        violations = r_healthy < r_sick\n",
    "        r_healthy[violations] = r_sick[violations] + self.epsilon\n",
    "        \n",
    "        return np.stack([r_sick, r_healthy], axis=1)\n",
    "\n",
    "\n",
    "class LagrangianMultiplier(ConstraintMethod):\n",
    "    \"\"\"Lagrangian method - adds penalty term to objective.\"\"\"\n",
    "    \n",
    "    def __init__(self, lambda_init=1.0, lambda_lr=0.01, epsilon=1e-3):\n",
    "        super().__init__(epsilon)\n",
    "        self.name = \"Lagrangian\"\n",
    "        self.lambda_penalty = lambda_init\n",
    "        self.lambda_lr = lambda_lr\n",
    "    \n",
    "    def get_penalty(self, rewards):\n",
    "        \"\"\"Compute penalty for constraint violations.\"\"\"\n",
    "        violations = np.maximum(0, rewards[:, 0] - rewards[:, 1] + self.epsilon)\n",
    "        penalty = self.lambda_penalty * np.sum(violations)\n",
    "        return penalty\n",
    "    \n",
    "    def update_lambda(self, rewards):\n",
    "        \"\"\"Update Lagrange multiplier based on constraint satisfaction.\"\"\"\n",
    "        violation_magnitude = np.mean(np.maximum(0, rewards[:, 0] - rewards[:, 1]))\n",
    "        self.lambda_penalty += self.lambda_lr * violation_magnitude\n",
    "        self.lambda_penalty = np.clip(self.lambda_penalty, 0.1, 100.0)\n",
    "    \n",
    "    def project(self, rewards):\n",
    "        \"\"\"Soft projection using current lambda.\"\"\"\n",
    "        r_sick = rewards[:, 0]\n",
    "        r_healthy = rewards[:, 1]\n",
    "        \n",
    "        # soft constraint\n",
    "        violations = r_healthy < r_sick\n",
    "        adjustment = self.lambda_penalty * (r_sick[violations] - r_healthy[violations])\n",
    "        r_healthy[violations] += adjustment * 0.1  # Gradual adjustment\n",
    "        \n",
    "        return np.stack([r_sick, r_healthy], axis=1)\n",
    "\n",
    "\n",
    "class LogBarrier(ConstraintMethod):\n",
    "    \"\"\"Log-barrier method - adds logarithmic penalty near constraint boundary.\"\"\"\n",
    "    \n",
    "    def __init__(self, mu=0.1, epsilon=1e-3):\n",
    "        super().__init__(epsilon)\n",
    "        self.name = \"Log_Barrier\"\n",
    "        self.mu = mu  # Barrier parameter\n",
    "    \n",
    "    def get_barrier(self, rewards):\n",
    "        \"\"\"Compute log-barrier penalty.\"\"\"\n",
    "        slack = rewards[:, 1] - rewards[:, 0] + self.epsilon\n",
    "        slack = np.maximum(slack, 1e-8)  # Avoid log(0)\n",
    "        barrier = -self.mu * np.sum(np.log(slack))\n",
    "        return barrier\n",
    "    \n",
    "    def project(self, rewards):\n",
    "        \"\"\"Apply barrier-based adjustment.\"\"\"\n",
    "        r_sick = rewards[:, 0]\n",
    "        r_healthy = rewards[:, 1]\n",
    "        \n",
    "        slack = r_healthy - r_sick + self.epsilon\n",
    "        violations = slack <= 0\n",
    "        \n",
    "        # For severe violations\n",
    "        if np.any(violations):\n",
    "            r_healthy[violations] = r_sick[violations] + 2 * self.epsilon\n",
    "        \n",
    "        return np.stack([r_sick, r_healthy], axis=1)\n",
    "\n",
    "\n",
    "class Unconstrained(ConstraintMethod):\n",
    "    \"\"\"Baseline: No constraints applied.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.name = \"Unconstrained\"\n",
    "    \n",
    "    def project(self, rewards):\n",
    "        \"\"\"No projection - return rewards as-is.\"\"\"\n",
    "        return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987a4c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.491898Z",
     "iopub.status.busy": "2025-12-13T07:31:28.491669Z",
     "iopub.status.idle": "2025-12-13T07:31:28.502659Z",
     "shell.execute_reply": "2025-12-13T07:31:28.502176Z"
    },
    "papermill": {
     "duration": 0.015916,
     "end_time": "2025-12-13T07:31:28.503676",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.487760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ABLATION - Test Without Aggregate Command\n",
    "\n",
    "def train_baseline_comparison(transitions, risk_scores, n_arms=500, n_folds=5, \n",
    "                              test_aggregate=True, constraint_method=None):\n",
    "    \"\"\"\n",
    "    Comparing violations with and without aggregate command.\n",
    "    \n",
    "    \"\"\"\n",
    "    from dfl.whittle import newWhittleIndex\n",
    "    from dfl.trajectory import getSimulatedTrajectories\n",
    "    from dfl.ope import eval_policy\n",
    "    \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    results_with_command = []\n",
    "    results_without_command = []\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"ABLATION STUDY: {'WITH' if test_aggregate else 'WITHOUT'} Aggregate Command\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(np.arange(n_arms))):\n",
    "        n_train = len(train_idx)\n",
    "        train_transitions = transitions[train_idx]\n",
    "        train_risk_scores = risk_scores[train_idx]\n",
    "        \n",
    "        # Generate baseline trajectories\n",
    "        reward_numpy = np.zeros((n_train, 2))\n",
    "        reward_numpy[:, 1] = 1\n",
    "        reward_opt = tf.constant(reward_numpy, dtype=tf.float32)\n",
    "        \n",
    "        w_opt = newWhittleIndex(\n",
    "            tf.constant(train_transitions, dtype=tf.float32),\n",
    "            reward_opt\n",
    "        ).numpy()\n",
    "        w_opt = np.reshape(w_opt, (n_train, 2))\n",
    "        \n",
    "        _, _, state_traj, action_traj, _ = getSimulatedTrajectories(\n",
    "            n_benefs=n_train, T=11, K=int(60 * n_train / n_arms),\n",
    "            n_trials=1, gamma=0.99, T_data=train_transitions,\n",
    "            R_data=reward_numpy, w=w_opt, replace=False,\n",
    "            policies=[3], fast=True\n",
    "        )\n",
    "        \n",
    "        # Test WITHOUT aggregate command\n",
    "        violations_without = test_irl_violations(\n",
    "            train_transitions, state_traj, action_traj, \n",
    "            w_opt, constraint_method, epochs=50\n",
    "        )\n",
    "        results_without_command.append(violations_without)\n",
    "        \n",
    "        # Test WITH aggregate command\n",
    "        if test_aggregate:\n",
    "            edited_action_traj = apply_aggregate_command(\n",
    "                action_traj, train_risk_scores, K=int(60 * n_train / n_arms)\n",
    "            )\n",
    "            violations_with = test_irl_violations(\n",
    "                train_transitions, state_traj, edited_action_traj,\n",
    "                w_opt, constraint_method, epochs=50\n",
    "            )\n",
    "            results_with_command.append(violations_with)\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1}: Without={violations_without:.1f}%, \" + \n",
    "              (f\"With={violations_with:.1f}%\" if test_aggregate else \"\"))\n",
    "    \n",
    "    return {\n",
    "        'without_command_mean': np.mean(results_without_command),\n",
    "        'without_command_std': np.std(results_without_command),\n",
    "        'with_command_mean': np.mean(results_with_command) if test_aggregate else None,\n",
    "        'with_command_std': np.std(results_with_command) if test_aggregate else None,\n",
    "        'all_without': results_without_command,\n",
    "        'all_with': results_with_command if test_aggregate else None\n",
    "    }\n",
    "\n",
    "\n",
    "def test_irl_violations(transitions, state_traj, action_traj, w_opt, \n",
    "                       constraint_method, epochs=50):\n",
    "    from dfl.whittle import newWhittleIndex\n",
    "    from dfl.ope import eval_policy\n",
    "    \n",
    "    n, n_states = transitions.shape[0], 2\n",
    "    rewards = np.zeros((n, n_states))\n",
    "    reward_param = tf.Variable(rewards, dtype=tf.float32)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            w = newWhittleIndex(\n",
    "                tf.constant(transitions, dtype=tf.float32), reward_param\n",
    "            )\n",
    "            w = tf.reshape(w, (n, n_states))\n",
    "            \n",
    "            performance, _, _, _, _ = eval_policy(\n",
    "                state_record=state_traj, action_record=action_traj,\n",
    "                w=w, w_opt=w_opt, H=10, K=int(60 * n / 500),\n",
    "                gamma=0.99, target_policy_name='soft-whittle',\n",
    "                beh_policy_name='soft-whittle',\n",
    "                transition_probabilities=transitions, epsilon=0.1,\n",
    "                reward_estimate=reward_param, rewards_true=None\n",
    "            )\n",
    "        \n",
    "        grads = tape.gradient(performance, reward_param)\n",
    "        optimizer.apply_gradients(zip([grads], [reward_param]))\n",
    "        \n",
    "        if constraint_method:\n",
    "            projected = constraint_method.project(reward_param.numpy())\n",
    "            reward_param.assign(projected)\n",
    "    \n",
    "    final_rewards = reward_param.numpy()\n",
    "    violations = np.sum(final_rewards[:, 1] < final_rewards[:, 0])\n",
    "    return (violations / n) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eafe76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.511128Z",
     "iopub.status.busy": "2025-12-13T07:31:28.510812Z",
     "iopub.status.idle": "2025-12-13T07:31:28.516867Z",
     "shell.execute_reply": "2025-12-13T07:31:28.516156Z"
    },
    "papermill": {
     "duration": 0.01108,
     "end_time": "2025-12-13T07:31:28.518030",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.506950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ground Truth Correlation Analysis\n",
    "\n",
    "def analyze_reward_quality(results, metadata):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GROUND TRUTH CORRELATION ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    correlations = {}\n",
    "    \n",
    "    for fold_idx, fold in enumerate(results['folds']):\n",
    "        train_idx = fold['train_idx']\n",
    "        true_grit = metadata['grit'][train_idx]\n",
    "        \n",
    "        for method_name, method_data in fold['methods'].items():\n",
    "            learned_rewards = method_data['learned_rewards']\n",
    "            r_healthy = learned_rewards[:, 1]  # Reward for adherence state\n",
    "            \n",
    "            # Correlation between learned R(healthy) and true grit\n",
    "            corr, p_value = stats.pearsonr(r_healthy, true_grit)\n",
    "            \n",
    "            if method_name not in correlations:\n",
    "                correlations[method_name] = []\n",
    "            correlations[method_name].append(corr)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nCorrelation: Learned R(Healthy) vs True Grit\")\n",
    "    print(\"(Higher correlation = better reward learning)\\n\")\n",
    "    \n",
    "    summary = []\n",
    "    for method_name, corrs in correlations.items():\n",
    "        mean_corr = np.mean(corrs)\n",
    "        std_corr = np.std(corrs)\n",
    "        summary.append({\n",
    "            'Method': method_name,\n",
    "            'Correlation (mean ± std)': f\"{mean_corr:.3f} ± {std_corr:.3f}\",\n",
    "            'Quality': '✓ Good' if mean_corr > 0.3 else '⚠ Weak'\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(summary)\n",
    "    print(df.to_string(index=False))\n",
    "    print(\"\\nInterpretation:\")\n",
    "    print(\"  > 0.5: Strong correlation - rewards capture adherence well\")\n",
    "    print(\"  0.3-0.5: Moderate - rewards partially capture adherence\")\n",
    "    print(\"  < 0.3: Weak - rewards may not be meaningful\")\n",
    "    \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa643785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.525252Z",
     "iopub.status.busy": "2025-12-13T07:31:28.525026Z",
     "iopub.status.idle": "2025-12-13T07:31:28.534897Z",
     "shell.execute_reply": "2025-12-13T07:31:28.534200Z"
    },
    "papermill": {
     "duration": 0.014863,
     "end_time": "2025-12-13T07:31:28.535984",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.521121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Beta Parameter Sensitivity Analysis\n",
    "\n",
    "def beta_sensitivity_experiment(n_arms=500, n_folds=3, epochs=30):\n",
    "    beta_profiles = [\n",
    "        (2, 2, \"Standard (U-shaped)\"),\n",
    "        (0.5, 0.5, \"Extreme Bimodal\"),\n",
    "        (5, 2, \"Right-skewed (High Grit)\"),\n",
    "        (2, 5, \"Left-skewed (Low Grit)\"),\n",
    "        (1, 1, \"Uniform\")\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"BETA PARAMETER SENSITIVITY ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    sensitivity_results = []\n",
    "    \n",
    "    for beta_a, beta_b, profile_name in beta_profiles:\n",
    "        print(f\"\\nTesting: {profile_name} (Beta({beta_a}, {beta_b}))\")\n",
    "        \n",
    "        transitions, metadata = generate_real_world_proxy_transitions(\n",
    "            n_arms, seed=SEED, beta_a=beta_a, beta_b=beta_b, \n",
    "            profile_name=profile_name\n",
    "        )\n",
    "        \n",
    "        validation = validate_data_quality(transitions, metadata)\n",
    "        print(f\"  Bimodality Coefficient: {validation['bimodality_coefficient']:.3f}\")\n",
    "        print(f\"  Grit Mean: {validation['grit_mean']:.3f} ± {validation['grit_std']:.3f}\")\n",
    "        \n",
    "        risk_scores = np.random.RandomState(SEED).randint(0, 4, size=n_arms)\n",
    "        \n",
    "        baseline_violations = []\n",
    "        constrained_violations = []\n",
    "        \n",
    "        # Quick 3-fold test per profile\n",
    "        kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        for fold_idx, (train_idx, _) in enumerate(kf.split(np.arange(n_arms))):\n",
    "            # Test baseline\n",
    "            v_baseline = quick_violation_test(\n",
    "                transitions[train_idx], risk_scores[train_idx],\n",
    "                use_constraint=False, epochs=epochs\n",
    "            )\n",
    "            baseline_violations.append(v_baseline)\n",
    "            \n",
    "            # Test with PGD\n",
    "            v_constrained = quick_violation_test(\n",
    "                transitions[train_idx], risk_scores[train_idx],\n",
    "                use_constraint=True, epochs=epochs\n",
    "            )\n",
    "            constrained_violations.append(v_constrained)\n",
    "        \n",
    "        sensitivity_results.append({\n",
    "            'Profile': profile_name,\n",
    "            'Beta': f\"({beta_a}, {beta_b})\",\n",
    "            'Baseline Violations (%)': f\"{np.mean(baseline_violations):.1f} ± {np.std(baseline_violations):.1f}\",\n",
    "            'PGD Violations (%)': f\"{np.mean(constrained_violations):.1f} ± {np.std(constrained_violations):.1f}\",\n",
    "            'Grit Mean': f\"{validation['grit_mean']:.3f}\"\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(sensitivity_results)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SENSITIVITY RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n\" + df.to_string(index=False))\n",
    "    \n",
    "    return sensitivity_results\n",
    "\n",
    "\n",
    "def quick_violation_test(transitions, risk_scores, use_constraint, epochs=30):\n",
    "    from dfl.whittle import newWhittleIndex\n",
    "    from dfl.trajectory import getSimulatedTrajectories\n",
    "    \n",
    "    n = len(transitions)\n",
    "    reward_numpy = np.zeros((n, 2))\n",
    "    reward_numpy[:, 1] = 1\n",
    "    \n",
    "    w_opt = newWhittleIndex(\n",
    "        tf.constant(transitions, dtype=tf.float32),\n",
    "        tf.constant(reward_numpy, dtype=tf.float32)\n",
    "    ).numpy()\n",
    "    w_opt = np.reshape(w_opt, (n, 2))\n",
    "    \n",
    "    _, _, state_traj, action_traj, _ = getSimulatedTrajectories(\n",
    "        n_benefs=n, T=11, K=int(60 * n / 500), n_trials=1, gamma=0.99,\n",
    "        T_data=transitions, R_data=reward_numpy, w=w_opt,\n",
    "        replace=False, policies=[3], fast=True\n",
    "    )\n",
    "    \n",
    "    edited_action = apply_aggregate_command(action_traj, risk_scores, K=int(60 * n / 500))\n",
    "    \n",
    "    constraint = ProjectedGradient() if use_constraint else None\n",
    "    violations_pct = test_irl_violations(\n",
    "        transitions, state_traj, edited_action, w_opt, constraint, epochs=epochs\n",
    "    )\n",
    "    \n",
    "    return violations_pct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde30fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.543558Z",
     "iopub.status.busy": "2025-12-13T07:31:28.543345Z",
     "iopub.status.idle": "2025-12-13T07:31:28.561661Z",
     "shell.execute_reply": "2025-12-13T07:31:28.561138Z"
    },
    "papermill": {
     "duration": 0.023386,
     "end_time": "2025-12-13T07:31:28.562600",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.539214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# K-FOLD TRAINING FRAMEWORK\n",
    "\n",
    "def train_whirl_with_constraint(\n",
    "    transition_probs,\n",
    "    state_traj,\n",
    "    action_traj,\n",
    "    w_opt,\n",
    "    constraint_method,\n",
    "    epochs=50,\n",
    "    learning_rate=0.01,\n",
    "    L=10,\n",
    "    K=60,\n",
    "    gamma=0.99,\n",
    "    verbose=False\n",
    "):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        transition_probs: Transition probability matrix\n",
    "        state_traj: State trajectories\n",
    "        action_traj: Action trajectories\n",
    "        w_opt: Optimal Whittle indices\n",
    "        constraint_method: ConstraintMethod instance\n",
    "        epochs: Number of training epochs\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        L: Time horizon\n",
    "        K: Budget constraint\n",
    "        gamma: Discount factor\n",
    "        verbose: Print training progress\n",
    "    \n",
    "    Returns:\n",
    "        learned_rewards: Final learned rewards\n",
    "        training_history: Dict with training metrics\n",
    "    \"\"\"\n",
    "    from dfl.whittle import newWhittleIndex\n",
    "    from dfl.ope import eval_policy\n",
    "    \n",
    "    n, n_states = transition_probs.shape[0], 2\n",
    "    \n",
    "    # Initialize rewards\n",
    "    rewards = np.zeros((n, n_states))\n",
    "    reward_param = tf.Variable(rewards, dtype=tf.float32)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'performance': [],\n",
    "        'violations': [],\n",
    "        'reward_norm': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Compute Whittle indices\n",
    "            w = newWhittleIndex(\n",
    "                tf.constant(transition_probs, dtype=tf.float32),\n",
    "                reward_param\n",
    "            )\n",
    "            w = tf.reshape(w, (n, n_states))\n",
    "            \n",
    "            # Evaluate policy\n",
    "            performance, _, _, _, _ = eval_policy(\n",
    "                state_record=state_traj,\n",
    "                action_record=action_traj,\n",
    "                w=w,\n",
    "                w_opt=w_opt,\n",
    "                H=L,\n",
    "                K=K,\n",
    "                gamma=gamma,\n",
    "                target_policy_name='soft-whittle',\n",
    "                beh_policy_name='soft-whittle',\n",
    "                transition_probabilities=transition_probs,\n",
    "                epsilon=0.1,\n",
    "                reward_estimate=reward_param,\n",
    "                rewards_true=None\n",
    "            )\n",
    "            \n",
    "            total_loss = performance\n",
    "            if hasattr(constraint_method, 'get_penalty'):\n",
    "                penalty = constraint_method.get_penalty(reward_param.numpy())\n",
    "                total_loss += penalty\n",
    "            elif hasattr(constraint_method, 'get_barrier'):\n",
    "                barrier = constraint_method.get_barrier(reward_param.numpy())\n",
    "                total_loss += barrier\n",
    "        \n",
    "        # Apply gradients\n",
    "        grads = tape.gradient(total_loss, reward_param)\n",
    "        optimizer.apply_gradients(zip([grads], [reward_param]))\n",
    "        \n",
    "        # Apply constraint projection\n",
    "        current_rewards = reward_param.numpy()\n",
    "        projected_rewards = constraint_method.project(current_rewards)\n",
    "        reward_param.assign(projected_rewards)\n",
    "        \n",
    "        # Update lambda for Lagrangian method\n",
    "        if isinstance(constraint_method, LagrangianMultiplier):\n",
    "            constraint_method.update_lambda(projected_rewards)\n",
    "        \n",
    "        # Log metrics\n",
    "        violations = constraint_method.check_violations(projected_rewards)\n",
    "        history['performance'].append(float(performance.numpy()))\n",
    "        history['violations'].append(violations)\n",
    "        history['reward_norm'].append(np.linalg.norm(projected_rewards))\n",
    "        \n",
    "        if verbose and epoch % 10 == 0:\n",
    "            print(f\"  Epoch {epoch}: Perf={performance.numpy():.4f}, \"\n",
    "                  f\"Violations={violations}, Norm={history['reward_norm'][-1]:.4f}\")\n",
    "    \n",
    "    return reward_param.numpy(), history\n",
    "\n",
    "\n",
    "def k_fold_experiment(\n",
    "    n_arms=500,\n",
    "    n_folds=5,\n",
    "    constraint_methods=None,\n",
    "    epochs=50,\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        n_arms: Number of beneficiaries\n",
    "        n_folds: Number of folds for cross-validation\n",
    "        constraint_methods: List of ConstraintMethod instances\n",
    "        epochs: Training epochs per fold\n",
    "        verbose: Print progress\n",
    "    \n",
    "    Returns:\n",
    "        results: Dict containing results for all methods and folds\n",
    "    \"\"\"\n",
    "    from dfl.whittle import newWhittleIndex\n",
    "    from dfl.trajectory import getSimulatedTrajectories\n",
    "    \n",
    "    if constraint_methods is None:\n",
    "        constraint_methods = [\n",
    "            Unconstrained(),\n",
    "            ProjectedGradient(),\n",
    "            LagrangianMultiplier(),\n",
    "            LogBarrier()\n",
    "        ]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING {n_folds}-FOLD CROSS-VALIDATION EXPERIMENT\")\n",
    "    print(f\"Arms: {n_arms}, Methods: {[m.name for m in constraint_methods]}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Generate full dataset\n",
    "    transitions, metadata = generate_real_world_proxy_transitions(n_arms, seed=SEED)\n",
    "    \n",
    "    # Validate data quality\n",
    "    validation_report = validate_data_quality(transitions, metadata)\n",
    "    print(\"Data Quality Report:\")\n",
    "    for key, val in validation_report.items():\n",
    "        print(f\"  {key}: {val}\")\n",
    "    print()\n",
    "    \n",
    "    # risk scores\n",
    "    risk_scores = np.random.RandomState(SEED).randint(0, 4, size=n_arms)\n",
    "    \n",
    "    # K-fold splits\n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Results storage\n",
    "    results = {\n",
    "        'transitions': transitions,\n",
    "        'metadata': metadata,\n",
    "        'risk_scores': risk_scores,\n",
    "        'validation_report': validation_report,\n",
    "        'folds': []\n",
    "    }\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(np.arange(n_arms))):\n",
    "        print(f\"\\n--- FOLD {fold_idx + 1}/{n_folds} ---\")\n",
    "        print(f\"Train size: {len(train_idx)}, Test size: {len(test_idx)}\")\n",
    "        \n",
    "        fold_results = {\n",
    "            'train_idx': train_idx,\n",
    "            'test_idx': test_idx,\n",
    "            'methods': {}\n",
    "        }\n",
    "        \n",
    "        n_train = len(train_idx)\n",
    "        train_transitions = transitions[train_idx]\n",
    "        \n",
    "        reward_numpy = np.zeros((n_train, 2))\n",
    "        reward_numpy[:, 1] = 1\n",
    "        reward_opt = tf.constant(reward_numpy, dtype=tf.float32)\n",
    "        \n",
    "        w_opt = newWhittleIndex(\n",
    "            tf.constant(train_transitions, dtype=tf.float32),\n",
    "            reward_opt\n",
    "        ).numpy()\n",
    "        w_opt = np.reshape(w_opt, (n_train, 2))\n",
    "        \n",
    "        _, _, state_traj, action_traj, _ = getSimulatedTrajectories(\n",
    "            n_benefs=n_train,\n",
    "            T=11,\n",
    "            K=int(60 * n_train / n_arms),  \n",
    "            n_trials=1,\n",
    "            gamma=0.99,\n",
    "            T_data=train_transitions,\n",
    "            R_data=reward_numpy,\n",
    "            w=w_opt,\n",
    "            replace=False,\n",
    "            policies=[3],\n",
    "            fast=True\n",
    "        )\n",
    "        \n",
    "        train_risk_scores = risk_scores[train_idx]\n",
    "        edited_action_traj = apply_aggregate_command(\n",
    "            action_traj, train_risk_scores, K=int(60 * n_train / n_arms)\n",
    "        )\n",
    "        \n",
    "        for method in constraint_methods:\n",
    "            print(f\"\\n  Training with {method.name}...\")\n",
    "            \n",
    "            learned_rewards, history = train_whirl_with_constraint(\n",
    "                transition_probs=train_transitions,\n",
    "                state_traj=state_traj,\n",
    "                action_traj=edited_action_traj,\n",
    "                w_opt=w_opt,\n",
    "                constraint_method=method,\n",
    "                epochs=epochs,\n",
    "                learning_rate=0.01,\n",
    "                L=10,\n",
    "                K=int(60 * n_train / n_arms),\n",
    "                gamma=0.99,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            test_violations = method.check_violations(learned_rewards)\n",
    "            \n",
    "            fold_results['methods'][method.name] = {\n",
    "                'learned_rewards': learned_rewards,\n",
    "                'training_history': history,\n",
    "                'test_violations': test_violations,\n",
    "                'final_performance': history['performance'][-1]\n",
    "            }\n",
    "            \n",
    "            print(f\"    Final violations: {test_violations}/{n_train}\")\n",
    "            print(f\"    Final performance: {history['performance'][-1]:.4f}\")\n",
    "        \n",
    "        results['folds'].append(fold_results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def apply_aggregate_command(action_traj, risk_scores, K=60, L=10):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        action_traj: Original action trajectories\n",
    "        risk_scores: Risk score for each beneficiary\n",
    "        K: Budget constraint\n",
    "        L: Time horizon\n",
    "    \n",
    "    Returns:\n",
    "        edited_action_traj: Modified action trajectories\n",
    "    \"\"\"\n",
    "    n = len(risk_scores)\n",
    "    edited_action_traj = np.copy(action_traj)\n",
    "    \n",
    "    for h in range(L):\n",
    "        # Finding beneficiaries to swap\n",
    "        called_low_risk = set()\n",
    "        uncalled_high_risk = set()\n",
    "        \n",
    "        for arm in range(n):\n",
    "            if edited_action_traj[0, 0, h, arm] == 1 and risk_scores[arm] in {0, 1}:\n",
    "                called_low_risk.add(arm)\n",
    "            if edited_action_traj[0, 0, h, arm] == 0 and risk_scores[arm] in {2, 3}:\n",
    "                uncalled_high_risk.add(arm)\n",
    "        \n",
    "        # Swaping with probability proportional to availability\n",
    "        if len(uncalled_high_risk) > 0 and len(called_low_risk) > 0:\n",
    "            prob_switch = min(len(called_low_risk) / len(uncalled_high_risk), 1.0)\n",
    "            \n",
    "            arms = np.arange(n)\n",
    "            np.random.shuffle(arms)\n",
    "            \n",
    "            for arm in arms:\n",
    "                if (arm in uncalled_high_risk and \n",
    "                    len(called_low_risk) > 0 and \n",
    "                    np.random.uniform() < prob_switch):\n",
    "                    \n",
    "                    edited_action_traj[0, 0, h, arm] = 1\n",
    "                    target = called_low_risk.pop()\n",
    "                    edited_action_traj[0, 0, h, target] = 0\n",
    "    \n",
    "    return edited_action_traj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f117e493",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.570059Z",
     "iopub.status.busy": "2025-12-13T07:31:28.569885Z",
     "iopub.status.idle": "2025-12-13T07:31:28.598678Z",
     "shell.execute_reply": "2025-12-13T07:31:28.598150Z"
    },
    "papermill": {
     "duration": 0.033786,
     "end_time": "2025-12-13T07:31:28.599608",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.565822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STATISTICAL ANALYSIS & VISUALIZATION\n",
    "\n",
    "def analyze_results(results):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        results: Dict from k_fold_experiment\n",
    "    \n",
    "    Returns:\n",
    "        analysis: Dict with statistical metrics\n",
    "    \"\"\"\n",
    "    n_folds = len(results['folds'])\n",
    "    method_names = list(results['folds'][0]['methods'].keys())\n",
    "    \n",
    "    analysis = {\n",
    "        'summary_stats': {},\n",
    "        'statistical_tests': {}\n",
    "    }\n",
    "    \n",
    "    # Aggregate metrics across folds\n",
    "    for method_name in method_names:\n",
    "        violations = []\n",
    "        performances = []\n",
    "        \n",
    "        for fold in results['folds']:\n",
    "            method_data = fold['methods'][method_name]\n",
    "            violations.append(method_data['test_violations'])\n",
    "            performances.append(method_data['final_performance'])\n",
    "        \n",
    "        violations = np.array(violations)\n",
    "        performances = np.array(performances)\n",
    "        \n",
    "        analysis['summary_stats'][method_name] = {\n",
    "            'violations_mean': np.mean(violations),\n",
    "            'violations_std': np.std(violations),\n",
    "            'violations_sem': stats.sem(violations),\n",
    "            'performance_mean': np.mean(performances),\n",
    "            'performance_std': np.std(performances),\n",
    "            'performance_sem': stats.sem(performances),\n",
    "            'violations_all': violations,\n",
    "            'performances_all': performances\n",
    "        }\n",
    "    \n",
    "    if 'Unconstrained' in method_names:\n",
    "        baseline_violations = analysis['summary_stats']['Unconstrained']['violations_all']\n",
    "        baseline_performance = analysis['summary_stats']['Unconstrained']['performances_all']\n",
    "        \n",
    "        for method_name in method_names:\n",
    "            if method_name == 'Unconstrained':\n",
    "                continue\n",
    "            \n",
    "            method_violations = analysis['summary_stats'][method_name]['violations_all']\n",
    "            method_performance = analysis['summary_stats'][method_name]['performances_all']\n",
    "            \n",
    "            # Wilcoxon signed-rank test for violations\n",
    "            violation_stat, violation_p = stats.wilcoxon(\n",
    "                baseline_violations, method_violations, alternative='greater'\n",
    "            )\n",
    "            \n",
    "            # Wilcoxon signed-rank test for performance\n",
    "            perf_stat, perf_p = stats.wilcoxon(\n",
    "                baseline_performance, method_performance, alternative='two-sided'\n",
    "            )\n",
    "            \n",
    "            analysis['statistical_tests'][method_name] = {\n",
    "                'violation_reduction_p_value': violation_p,\n",
    "                'violation_statistic': violation_stat,\n",
    "                'performance_difference_p_value': perf_p,\n",
    "                'performance_statistic': perf_stat\n",
    "            }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "\n",
    "def plot_comprehensive_results(results, analysis, save_path=None):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        results: Dict from k_fold_experiment\n",
    "        analysis: Dict from analyze_results\n",
    "        save_path: Optional path to save figure\n",
    "    \"\"\"\n",
    "    method_names = list(analysis['summary_stats'].keys())\n",
    "    n_methods = len(method_names)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # Color palette\n",
    "    colors = sns.color_palette(\"husl\", n_methods)\n",
    "    method_colors = {name: colors[i] for i, name in enumerate(method_names)}\n",
    "    \n",
    "    # ---- Row 1: Violations and Performance ----\n",
    "    \n",
    "    # Plot 1: Violation rates across folds\n",
    "    ax1 = fig.add_subplot(gs[0, 0:2])\n",
    "    violation_data = []\n",
    "    for method_name in method_names:\n",
    "        violations = analysis['summary_stats'][method_name]['violations_all']\n",
    "        for fold_idx, v in enumerate(violations):\n",
    "            violation_data.append({\n",
    "                'Method': method_name,\n",
    "                'Fold': fold_idx + 1,\n",
    "                'Violations': v\n",
    "            })\n",
    "    \n",
    "    df_violations = pd.DataFrame(violation_data)\n",
    "    sns.boxplot(data=df_violations, x='Method', y='Violations', ax=ax1, palette=method_colors)\n",
    "    ax1.set_title('Constraint Violations Across Folds', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Violations')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Plot 2: Performance comparison\n",
    "    ax2 = fig.add_subplot(gs[0, 2:4])\n",
    "    performance_data = []\n",
    "    for method_name in method_names:\n",
    "        perfs = analysis['summary_stats'][method_name]['performances_all']\n",
    "        for fold_idx, p in enumerate(perfs):\n",
    "            performance_data.append({\n",
    "                'Method': method_name,\n",
    "                'Fold': fold_idx + 1,\n",
    "                'Performance': p\n",
    "            })\n",
    "    \n",
    "    df_performance = pd.DataFrame(performance_data)\n",
    "    sns.violinplot(data=df_performance, x='Method', y='Performance', ax=ax2, palette=method_colors)\n",
    "    ax2.set_title('Policy Performance Across Folds', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Performance Score')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # ---- Row 2: Training Dynamics ----\n",
    "    \n",
    "    # Plot 3: Training curves (violations over epochs)\n",
    "    ax3 = fig.add_subplot(gs[1, 0:2])\n",
    "    for method_name in method_names:\n",
    "        fold_0_history = results['folds'][0]['methods'][method_name]['training_history']\n",
    "        ax3.plot(fold_0_history['violations'], \n",
    "                label=method_name, \n",
    "                color=method_colors[method_name],\n",
    "                linewidth=2)\n",
    "    ax3.set_title('Violation Trajectory During Training (Fold 1)', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Epoch')\n",
    "    ax3.set_ylabel('Number of Violations')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 4: Training curves (performance over epochs)\n",
    "    ax4 = fig.add_subplot(gs[1, 2:4])\n",
    "    for method_name in method_names:\n",
    "        fold_0_history = results['folds'][0]['methods'][method_name]['training_history']\n",
    "        ax4.plot(fold_0_history['performance'], \n",
    "                label=method_name,\n",
    "                color=method_colors[method_name],\n",
    "                linewidth=2)\n",
    "    ax4.set_title('Performance Trajectory During Training (Fold 1)', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Epoch')\n",
    "    ax4.set_ylabel('Performance')\n",
    "    ax4.legend()\n",
    "    ax4.grid(alpha=0.3)\n",
    "    \n",
    "    # ---- Row 3: Reward Analysis and Statistical Tests ----\n",
    "    \n",
    "    # Plot 5: Learned reward distributions (Fold 1, Projected Gradient)\n",
    "    ax5 = fig.add_subplot(gs[2, 0:2])\n",
    "    if 'Projected_Gradient' in method_names:\n",
    "        pg_rewards = results['folds'][0]['methods']['Projected_Gradient']['learned_rewards']\n",
    "        ax5.scatter(pg_rewards[:, 0], pg_rewards[:, 1], \n",
    "                   alpha=0.6, s=20, c='blue', label='Learned Rewards')\n",
    "        \n",
    "        # Add constraint line (y = x)\n",
    "        lims = [min(pg_rewards.min(), -0.5), max(pg_rewards.max(), 1.5)]\n",
    "        ax5.plot(lims, lims, 'r--', linewidth=2, label='Constraint Boundary (R₁=R₀)')\n",
    "        \n",
    "        ax5.set_xlabel('R(State=0) - Dropout')\n",
    "        ax5.set_ylabel('R(State=1) - Adherence')\n",
    "        ax5.set_title('Reward Space: Projected Gradient (Fold 1)', fontsize=14, fontweight='bold')\n",
    "        ax5.legend()\n",
    "        ax5.grid(alpha=0.3)\n",
    "    \n",
    "    # Plot 6: Statistical significance heatmap\n",
    "    ax6 = fig.add_subplot(gs[2, 2:4])\n",
    "    if 'statistical_tests' in analysis and len(analysis['statistical_tests']) > 0:\n",
    "        test_methods = list(analysis['statistical_tests'].keys())\n",
    "        p_values_violations = [analysis['statistical_tests'][m]['violation_reduction_p_value'] \n",
    "                              for m in test_methods]\n",
    "        p_values_performance = [analysis['statistical_tests'][m]['performance_difference_p_value'] \n",
    "                               for m in test_methods]\n",
    "        \n",
    "        heatmap_data = np.array([p_values_violations, p_values_performance]).T\n",
    "        sns.heatmap(heatmap_data, \n",
    "                   annot=True, \n",
    "                   fmt='.4f', \n",
    "                   xticklabels=['Violation\\nReduction', 'Performance\\nDifference'],\n",
    "                   yticklabels=test_methods,\n",
    "                   cmap='RdYlGn_r',\n",
    "                   vmin=0, \n",
    "                   vmax=0.1,\n",
    "                   ax=ax6,\n",
    "                   cbar_kws={'label': 'p-value'})\n",
    "        ax6.set_title('Statistical Tests vs Unconstrained (p-values)', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.suptitle('Constitutional WHIRL: Comprehensive Experimental Results', \n",
    "                fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def print_summary_table(analysis):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        analysis: Dict from analyze_results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY TABLE: K-FOLD CROSS-VALIDATION RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create summary dataframe\n",
    "    summary_data = []\n",
    "    for method_name, stats_dict in analysis['summary_stats'].items():\n",
    "        summary_data.append({\n",
    "            'Method': method_name,\n",
    "            'Violations (Mean ± SEM)': f\"{stats_dict['violations_mean']:.2f} ± {stats_dict['violations_sem']:.2f}\",\n",
    "            'Violations (%)': f\"{(stats_dict['violations_mean']/500)*100:.1f}%\",\n",
    "            'Performance (Mean ± SEM)': f\"{stats_dict['performance_mean']:.4f} ± {stats_dict['performance_sem']:.4f}\",\n",
    "            'Violation Reduction': 'Baseline' if method_name == 'Unconstrained' else \n",
    "                                   f\"{((analysis['summary_stats']['Unconstrained']['violations_mean'] - stats_dict['violations_mean'])/analysis['summary_stats']['Unconstrained']['violations_mean']*100):.1f}%\"\n",
    "        })\n",
    "    \n",
    "    df_summary = pd.DataFrame(summary_data)\n",
    "    print(\"\\n\" + df_summary.to_string(index=False))\n",
    "    \n",
    "    # Statistical significance table\n",
    "    if 'statistical_tests' in analysis and len(analysis['statistical_tests']) > 0:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"STATISTICAL SIGNIFICANCE TESTS (vs Unconstrained Baseline)\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        sig_data = []\n",
    "        for method_name, test_results in analysis['statistical_tests'].items():\n",
    "            violation_p = test_results['violation_reduction_p_value']\n",
    "            perf_p = test_results['performance_difference_p_value']\n",
    "            \n",
    "            sig_data.append({\n",
    "                'Method': method_name,\n",
    "                'Violation Reduction': 'p < 0.001 ***' if violation_p < 0.001 else\n",
    "                                      f'p < 0.01 **' if violation_p < 0.01 else\n",
    "                                      f'p < 0.05 *' if violation_p < 0.05 else\n",
    "                                      f'p = {violation_p:.4f} (n.s.)',\n",
    "                'Performance Difference': 'p < 0.001 ***' if perf_p < 0.001 else\n",
    "                                         f'p < 0.01 **' if perf_p < 0.01 else\n",
    "                                         f'p < 0.05 *' if perf_p < 0.05 else\n",
    "                                         f'p = {perf_p:.4f} (n.s.)',\n",
    "                'Interpretation': '✓ Significantly safer' if violation_p < 0.05 else '✗ Not significant'\n",
    "            })\n",
    "        \n",
    "        df_sig = pd.DataFrame(sig_data)\n",
    "        print(\"\\n\" + df_sig.to_string(index=False))\n",
    "        print(\"\\nNote: *** p<0.001, ** p<0.01, * p<0.05, n.s. = not significant\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "\n",
    "def generate_latex_table(analysis, caption=\"K-Fold Cross-Validation Results\"):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        analysis: Dict from analyze_results\n",
    "        caption: Table caption\n",
    "    \n",
    "    Returns:\n",
    "        latex_str: LaTeX table code\n",
    "    \"\"\"\n",
    "    latex_str = \"\\\\begin{table}[htbp]\\n\"\n",
    "    latex_str += \"\\\\centering\\n\"\n",
    "    latex_str += f\"\\\\caption{{{caption}}}\\n\"\n",
    "    latex_str += \"\\\\label{tab:results}\\n\"\n",
    "    latex_str += \"\\\\begin{tabular}{lccc}\\n\"\n",
    "    latex_str += \"\\\\toprule\\n\"\n",
    "    latex_str += \"Method & Violations (\\\\%) & Performance & Significance \\\\\\\\\\n\"\n",
    "    latex_str += \"\\\\midrule\\n\"\n",
    "    \n",
    "    for method_name, stats_dict in analysis['summary_stats'].items():\n",
    "        violations_pct = (stats_dict['violations_mean']/500)*100\n",
    "        perf_mean = stats_dict['performance_mean']\n",
    "        perf_sem = stats_dict['performance_sem']\n",
    "        \n",
    "        # Significance marker\n",
    "        sig_marker = \"\"\n",
    "        if method_name in analysis.get('statistical_tests', {}):\n",
    "            p_val = analysis['statistical_tests'][method_name]['violation_reduction_p_value']\n",
    "            if p_val < 0.001:\n",
    "                sig_marker = \"$^{***}$\"\n",
    "            elif p_val < 0.01:\n",
    "                sig_marker = \"$^{**}$\"\n",
    "            elif p_val < 0.05:\n",
    "                sig_marker = \"$^{*}$\"\n",
    "        \n",
    "        latex_str += f\"{method_name.replace('_', ' ')} & {violations_pct:.1f}\\\\% & \"\n",
    "        latex_str += f\"{perf_mean:.4f} $\\\\pm$ {perf_sem:.4f} & {sig_marker} \\\\\\\\\\n\"\n",
    "    \n",
    "    latex_str += \"\\\\bottomrule\\n\"\n",
    "    latex_str += \"\\\\end{tabular}\\n\"\n",
    "    latex_str += \"\\\\end{table}\\n\"\n",
    "    \n",
    "    return latex_str\n",
    "\n",
    "\n",
    "def plot_reward_landscape_comparison(results, fold_idx=0):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        results: Dict from k_fold_experiment\n",
    "        fold_idx: Which fold to visualize\n",
    "    \"\"\"\n",
    "    fold = results['folds'][fold_idx]\n",
    "    method_names = list(fold['methods'].keys())\n",
    "    n_methods = len(method_names)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_methods, figsize=(5*n_methods, 4))\n",
    "    if n_methods == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, method_name in enumerate(method_names):\n",
    "        ax = axes[idx]\n",
    "        rewards = fold['methods'][method_name]['learned_rewards']\n",
    "        \n",
    "        # Scatter plot\n",
    "        ax.scatter(rewards[:, 0], rewards[:, 1], \n",
    "                  alpha=0.5, s=15, c='steelblue', edgecolors='none')\n",
    "        \n",
    "        # Constraint boundary\n",
    "        lims = [min(rewards.min(), -0.5), max(rewards.max(), 1.5)]\n",
    "        ax.plot(lims, lims, 'r--', linewidth=2, label='R₁ = R₀', alpha=0.7)\n",
    "        \n",
    "        # Shade feasible region\n",
    "        ax.fill_between(lims, lims, lims[1], alpha=0.1, color='green', label='Feasible')\n",
    "        ax.fill_between(lims, lims[0], lims, alpha=0.1, color='red', label='Infeasible')\n",
    "        \n",
    "        # Count violations\n",
    "        violations = np.sum(rewards[:, 1] < rewards[:, 0])\n",
    "        \n",
    "        ax.set_xlabel('R(Dropout)', fontsize=11)\n",
    "        ax.set_ylabel('R(Adherence)', fontsize=11)\n",
    "        ax.set_title(f'{method_name.replace(\"_\", \" \")}\\n({violations} violations)', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.legend(loc='upper left', fontsize=9)\n",
    "        ax.grid(alpha=0.3)\n",
    "        ax.set_aspect('equal')\n",
    "    \n",
    "    plt.suptitle(f'Learned Reward Landscapes (Fold {fold_idx+1})', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def export_results_to_csv(results, analysis, filename='constitutional_whirl_results.csv'):\n",
    "    \"\"\"    \n",
    "    Args:\n",
    "        results: Dict from k_fold_experiment\n",
    "        analysis: Dict from analyze_results\n",
    "        filename: Output filename\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for fold_idx, fold in enumerate(results['folds']):\n",
    "        for method_name, method_data in fold['methods'].items():\n",
    "            rows.append({\n",
    "                'fold': fold_idx + 1,\n",
    "                'method': method_name,\n",
    "                'violations': method_data['test_violations'],\n",
    "                'performance': method_data['final_performance'],\n",
    "                'violations_pct': (method_data['test_violations'] / len(fold['train_idx'])) * 100\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"\\nResults exported to {filename}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f231db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T07:31:28.607016Z",
     "iopub.status.busy": "2025-12-13T07:31:28.606813Z",
     "iopub.status.idle": "2025-12-13T12:56:02.441439Z",
     "shell.execute_reply": "2025-12-13T12:56:02.440746Z"
    },
    "papermill": {
     "duration": 19473.83979,
     "end_time": "2025-12-13T12:56:02.442629",
     "exception": false,
     "start_time": "2025-12-13T07:31:28.602839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MAIN EXECUTION WITH ALL ABLATIONS\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"CONSTITUTIONAL WHIRL: COMPLETE EXPERIMENTAL FRAMEWORK\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # EXPERIMENT 1: The Core Question - Aggregate Command Impact\n",
    "    print(\"\\n\\n### EXPERIMENT 1: AGGREGATE COMMAND ABLATION ###\")\n",
    "    print(\"Question: Is the violation rate caused by IRL or the aggregate command?\\n\")\n",
    "    \n",
    "    transitions, metadata = generate_real_world_proxy_transitions(500, seed=SEED)\n",
    "    risk_scores = np.random.RandomState(SEED).randint(0, 4, size=500)\n",
    "    \n",
    "    ablation_results = train_baseline_comparison(\n",
    "        transitions, risk_scores, n_arms=500, n_folds=5, \n",
    "        test_aggregate=True, constraint_method=None\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ABLATION RESULTS: WITH vs WITHOUT Aggregate Command\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"WITHOUT Command: {ablation_results['without_command_mean']:.1f}% ± {ablation_results['without_command_std']:.1f}%\")\n",
    "    print(f\"WITH Command:    {ablation_results['with_command_mean']:.1f}% ± {ablation_results['with_command_std']:.1f}%\")\n",
    "    \n",
    "    # Statistical test\n",
    "    if ablation_results['all_with']:\n",
    "        stat, p_val = stats.wilcoxon(\n",
    "            ablation_results['all_without'],\n",
    "            ablation_results['all_with'],\n",
    "            alternative='less'\n",
    "        )\n",
    "        print(f\"\\nWilcoxon test: p = {p_val:.4f}\")\n",
    "        if p_val < 0.05:\n",
    "            print(\"✓ Aggregate command SIGNIFICANTLY increases violations\")\n",
    "        else:\n",
    "            print(\"✗ No significant difference - problem is inherent to IRL\")\n",
    "    \n",
    "    # EXPERIMENT 2: Beta Parameter Sensitivity\n",
    "    print(\"\\n\\n### EXPERIMENT 2: BETA PARAMETER SENSITIVITY ###\")\n",
    "    print(\"Question: Are results robust across different population distributions?\\n\")\n",
    "    \n",
    "    sensitivity_results = beta_sensitivity_experiment(\n",
    "        n_arms=500, n_folds=3, epochs=30\n",
    "    )\n",
    "    \n",
    "    # EXPERIMENT 3: Full K-Fold with All Constraint Methods\n",
    "    print(\"\\n\\n### EXPERIMENT 3: FULL K-FOLD EVALUATION ###\")\n",
    "    print(\"Question: Which constraint method works best?\\n\")\n",
    "    \n",
    "    constraint_methods = [\n",
    "        Unconstrained(),\n",
    "        ProjectedGradient(epsilon=0.001),\n",
    "        LagrangianMultiplier(lambda_init=1.0, lambda_lr=0.01),\n",
    "        LogBarrier(mu=0.1)\n",
    "    ]\n",
    "    \n",
    "    full_results = k_fold_experiment(\n",
    "        n_arms=500, n_folds=5, constraint_methods=constraint_methods,\n",
    "        epochs=50, verbose=True\n",
    "    )\n",
    "    \n",
    "    analysis = analyze_results(full_results)\n",
    "    \n",
    "    # EXPERIMENT 4: Ground Truth Correlation\n",
    "    print(\"\\n\\n### EXPERIMENT 4: REWARD QUALITY ANALYSIS ###\")\n",
    "    print(\"Question: Do learned rewards correlate with true adherence propensity?\\n\")\n",
    "    \n",
    "    correlations = analyze_reward_quality(full_results, metadata)\n",
    "    \n",
    "    # All Outputs\n",
    "    print(\"\\n\\n### GENERATING OUTPUTS ###\")\n",
    "    \n",
    "    print_summary_table(analysis)\n",
    "    plot_comprehensive_results(full_results, analysis, \n",
    "                               save_path='constitutional_whirl_full.png')\n",
    "    plot_reward_landscape_comparison(full_results, fold_idx=0)\n",
    "    export_results_to_csv(full_results, analysis)\n",
    "    \n",
    "    latex = generate_latex_table(analysis)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LATEX TABLE\")\n",
    "    print(\"=\"*80)\n",
    "    print(latex)\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(\"\\n### Key Findings:\")\n",
    "    print(f\"1. Baseline IRL violation rate: {ablation_results['with_command_mean']:.1f}%\")\n",
    "    print(f\"   - WITHOUT aggregate command: {ablation_results['without_command_mean']:.1f}%\")\n",
    "    print(f\"   - Aggregate command {'significantly increases' if p_val < 0.05 else 'does not affect'} violations\")\n",
    "    \n",
    "    print(f\"\\n2. Projected Gradient method:\")\n",
    "    pgd_stats = analysis['summary_stats']['Projected_Gradient']\n",
    "    print(f\"   - Reduces violations to {pgd_stats['violations_mean']:.1f}%\")\n",
    "    print(f\"   - Performance: {pgd_stats['performance_mean']:.2f} ± {pgd_stats['performance_sem']:.2f}\")\n",
    "    \n",
    "    print(f\"\\n3. Reward quality:\")\n",
    "    pgd_corr = np.mean(correlations.get('Projected_Gradient', [0]))\n",
    "    print(f\"   - Correlation with true grit: {pgd_corr:.3f}\")\n",
    "    print(f\"   - Rewards {'are' if pgd_corr > 0.3 else 'may not be'} meaningful\")\n",
    "    \n",
    "    print(\"\\n### Limitations:\")\n",
    "    print(\"   - Synthetic data (Beta distributions)\")\n",
    "    print(\"   - N=5 folds limits statistical power\")\n",
    "    print(\"   - Aggregate command may introduce artifacts\")\n",
    "    \n",
    "    print(\"\\n### Next Steps:\")\n",
    "    print(\"   - Validate on real maternal health data\")\n",
    "    print(\"   - Test with N=10+ folds or multiple seeds\")\n",
    "    print(\"   - Extend to multi-state (n_states > 2)\")\n",
    "    print(\"   - Compare with Safe RL baselines (CPO, RCPO)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXPERIMENT COMPLETE!\")\n",
    "    print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8926580,
     "sourceId": 14012382,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19502.18612,
   "end_time": "2025-12-13T12:56:05.189885",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-13T07:31:03.003765",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
